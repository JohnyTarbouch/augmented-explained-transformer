% This is a variation of the NeurIPS'24 format
\documentclass{article}
\usepackage[final]{adrl}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}     
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{Explanation Consistency of DistilBERT Sentiment Analysis\\Under Text Data Augmentation}

% TODO: Update GitHub URL to your actual repository
\author{Johny Tarbouch \\ \url{https://github.com/JohnyTarbouch/Augmented-Explained-Transformer}}

\begin{document}

\maketitle

\section{Motivation}
Transformer models are powerful, but they are also black boxes, making their internal decision-making processes difficult to interpret. To address this issue, attention scores are often used as a means of explaining model behavior; however, raw attention weights have been shown to be unreliable explanations~\cite{jain2019attention, wiegreffe2019attention}. Beyond attention-based approaches, post-hoc explanation methods such as Integrated Gradients (IG) are widely used to interpret transformer-based models. However, the \textit{consistency} of these explanations under semantically equivalent inputs remains underexplored. If a model correctly classifies both an original sentence and its augmented variant with the same sentiment, one would expect the explanations to highlight similar tokens. Inconsistent attributions would raise concerns about the reliability of explanation methods for downstream applications such as model debugging and bias detection. This project investigates whether training with augmented data improves the consistency of token-level attributions, thereby providing insights into the trustworthiness of gradient-based explanation methods for NLP.

\section{Related Topics}

\paragraph{Feature Importance.} The lecture introduced global and local feature importance methods. Integrated Gradients~\cite{sundararajan2017axiomatic} computes attributions by integrating gradients along the path from a baseline to the input, satisfying key axioms such as sensitivity and implementation invariance.

\paragraph{Post-hoc Methods for DNNs.} Chefer et al.~\cite{chefer2021transformer} demonstrated that combining relevancy propagation with attention gradients produces more faithful explanations for transformers than attention alone, establishing that careful methodology is required when interpreting transformer predictions.

\paragraph{Explanation Faithfulness \& Evaluation.} The ERASER benchmark~\cite{deyoung2020eraser} introduced metrics such as \textit{sufficiency} and \textit{comprehensiveness} to evaluate explanation quality. We adapt similar evaluation paradigms to measure consistency across input perturbations.

\paragraph{Data Augmentation.} Wei \& Zou~\cite{wei2019eda} simple text augmentation techniques can not improve classification performance for transformer model. Our focus is on explainability, not improving accuracy.

\section{Idea}

We evaluate whether training with augmented data produces a model with more consistent token-level explanations when the input text is modified using semantically-preserving augmentations. Our main research question is:

\begin{quote}
\textit{Does training with augmented data produce a model that gives more consistent Integrated Gradient explanations when evaluated on original-augmented text pairs?}
\end{quote}

\textbf{Approach:}
\begin{enumerate}
    \item Fine-tune $f_{\text{orig}}$ on original SST-2 training data.
    \item Fine-tune $f_{\text{aug}}$ on SST-2 + synonym-replaced augmented data.
    \item For each test sample, generate an augmented version.
    \item Filter pairs where both models predict the same label for both texts.
    \item Compute IG attributions for both texts under both models.
    \item Compare consistency metrics: $f_{\text{aug}}$ vs $f_{\text{orig}}$.
\end{enumerate}

\begin{algorithm}[H]
    \caption{Explanation Consistency Comparison}
    \label{alg:consistency}
    \begin{algorithmic}
        \Require Test set $\mathcal{D} = \{(x_i, y_i)\}$, models $f_{\text{orig}}$, $f_{\text{aug}}$, augmentation function $\mathcal{A}$
        \State Initialize consistency scores $\mathcal{S}_{\text{orig}} \gets \emptyset$, $\mathcal{S}_{\text{aug}} \gets \emptyset$
        \For{each $(x, y) \in \mathcal{D}$}
            \State $x' \gets \mathcal{A}(x)$ 
            \State $p_{\text{orig}} \gets \arg\max f_{\text{orig}}(x)$, \quad $p'_{\text{orig}} \gets \arg\max f_{\text{orig}}(x')$
            \State $p_{\text{aug}} \gets \arg\max f_{\text{aug}}(x)$, \quad $p'_{\text{aug}} \gets \arg\max f_{\text{aug}}(x')$
            \If{$p_{\text{orig}} = p'_{\text{orig}} = p_{\text{aug}} = p'_{\text{aug}}$} 
                \For{$f \in \{f_{\text{orig}}, f_{\text{aug}}\}$}
                    \State $\alpha \gets \text{IG}(f, x)$, \quad $\alpha' \gets \text{IG}(f, x')$
                    \State $\alpha_{\text{align}}, \alpha'_{\text{align}} \gets \text{Align}(\alpha, \alpha', x, x')$
                    \State $s \gets \text{Consistency}(\alpha_{\text{align}}, \alpha'_{\text{align}})$
                    \State Append $s$ to corresponding $\mathcal{S}_f$
                \EndFor
            \EndIf
        \EndFor
        \Return $\text{Mean}(\mathcal{S}_{\text{orig}})$, $\text{Mean}(\mathcal{S}_{\text{aug}})$
    \end{algorithmic}
\end{algorithm}

\paragraph{Consistency Metrics.} For aligned attribution vectors $\alpha$ and $\alpha'$:
\begin{equation}
    \text{RankCorr}(\alpha, \alpha') = \tau(\text{rank}(\alpha), \text{rank}(\alpha'))
    \label{eq:kendall}
\end{equation}
where $\tau$ denotes Kendall's tau correlation. Additionally, we compute Top-$k$ Overlap ($|\text{Top}_k(\alpha) \cap \text{Top}_k(\alpha')| / k$) and Cosine Similarity ($\cos(\alpha, \alpha')$).

\paragraph{Token Alignment.} Since augmentations may change sentence length, we align tokens using exact string matching for unchanged tokens and WordNet-based synonym matching for replaced tokens.

\section{Experiments}

\paragraph{Dataset.} We use \textbf{SST-2} (Stanford Sentiment Treebank)~\cite{socher2013recursive}, a binary sentiment classification benchmark. Its short sentences (~19 tokens) enable efficient IG computation and clear visualization.

\paragraph{Experimental Scope.} 
\begin{itemize}
    \item Models: $f_{\text{orig}}$, $f_{\text{aug}}$ (both \texttt{distilbert-base-uncased})
    \item Training: 3--4 epochs, batch size 16, learning rate $2 \times 10^{-5}$
    \item Augmentation: Synonym replacement on 10\% of tokens per sentence
    \item Augmented training set: original + 1 augmented copy per sample
    \item Test set: 500 samples from SST-2 validation
    \item Seeds: 1 random seeds (42) for training and augmentation
\end{itemize}

\paragraph{Computational Resources.} All experiments can be run on Google Colab or a personal machine with RTX 3060TI.

\section{Timeline}

\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Days 1--2} & Literature review, codebase setup, data preprocessing \\
\textbf{Days 3--5} & Implement augmentation, fine-tune both BERT models \\
\textbf{Days 6--9} & Implement IG with Captum, run attribution extraction \\
\textbf{Days 10--11} & Compute consistency metrics, statistical analysis, visualizations \\
\textbf{Days 12--14} & Report, poster, code documentation \\
\bottomrule
\end{tabular}

\bibliographystyle{plain}
\bibliography{references}

\end{document}
