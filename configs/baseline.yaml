project:
  name: augmented-explained-transformer
  seed: 42
  run_id: baseline

data:
  dataset: sst2
  cache_dir: data/raw/hf_cache
  output_dir: data/raw/sst2
  max_length: 128

augmentation:
  enabled: true
  replace_prob: 0.1

model:
  name: distilbert-base-uncased-finetuned-sst-2-english
  num_labels: 2

training:
  epochs: 2
  batch_size: 32
  lr: 2e-5
  weight_decay: 0.01
  output_dir: models/baseline
  skip_train: true
  device: cuda
  train_data_path: data/raw/sst2/train.csv
  eval_data_path: data/raw/sst2/validation.csv
  text_column: sentence
  label_column: label
  lora:
    enabled: false
    r: 8
    alpha: 16
    dropout: 0.1
    target_modules: [q_lin, k_lin, v_lin, out_lin]

evaluation:
  split: validation
  output_dir: reports/metrics
  device: cuda
  model_path: distilbert-base-uncased-finetuned-sst-2-english

explain:
  method: integrated_gradients
  n_steps: 50
  top_k: 10
  split: validation
  max_samples: 50
  output_dir: reports/attributions
  device: cuda
  data_path: null
  text_column: sentence
  model_path: distilbert-base-uncased-finetuned-sst-2-english

consistency:
  split: validation
  max_samples: 200
  output_dir: reports/metrics
  figures_dir: reports/figures
  device: cuda
  checks: [continuity, determinism, invariance]
  determinism_repeats: 3
  model_a: distilbert-base-uncased-finetuned-sst-2-english
  model_b: null
  model_path: distilbert-base-uncased-finetuned-sst-2-english

faithfulness:
  split: validation
  max_samples: 200
  output_dir: reports/metrics
  figures_dir: reports/figures
  device: cuda
  step_fraction: 0.1
  random_repeats: 5
  mask_strategy: mask

robustness:
  split: validation
  max_samples: 200
  output_dir: reports/metrics
  device: cuda
  attack: textfooler
  model_path: distilbert-base-uncased-finetuned-sst-2-english
  data_path: null
  text_column: sentence
  label_column: label

counterfactual:
  split: validation
  max_samples: 200
  max_saved: 200
  output_dir: reports/metrics
  device: cuda
  attack: textfooler
  model_path: distilbert-base-uncased-finetuned-sst-2-english
  data_path: null
  text_column: sentence
  label_column: label

attention:
  split: validation
  max_samples: 200
  output_dir: reports/metrics
  figures_dir: reports/figures
  device: cuda
  layer: last
  top_k: 10
  checks: [consistency, ig_alignment]
  model_path: distilbert-base-uncased-finetuned-sst-2-english

lime:
  split: validation
  max_samples: 200
  output_dir: reports/metrics
  figures_dir: reports/figures
  device: cuda
  num_samples: 500
  max_features: null
  top_k: 10
  data_path: null
  text_column: sentence
  model_path: distilbert-base-uncased-finetuned-sst-2-english

tracking:
  mlflow_uri: file:./mlruns
  experiment: aet
